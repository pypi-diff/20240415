# Comparing `tmp/finter-0.1.9-py3-none-any.whl.zip` & `tmp/finter-0.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,69 +1,84 @@
-Zip file size: 186762 bytes, number of entries: 130
--rw-r--r--  2.0 unx     3693 b- defN 24-Feb-22 23:47 finter/__init__.py
+Zip file size: 207500 bytes, number of entries: 145
+-rw-r--r--  2.0 unx     4121 b- defN 24-Apr-08 00:23 finter/__init__.py
 -rw-r--r--  2.0 unx    25315 b- defN 24-Feb-19 14:06 finter/api_client.py
 -rw-r--r--  2.0 unx     8871 b- defN 24-Feb-19 14:06 finter/configuration.py
 -rw-r--r--  2.0 unx    13299 b- defN 24-Feb-19 14:06 finter/rest.py
--rw-r--r--  2.0 unx     1590 b- defN 24-Mar-04 03:21 finter/settings.py
+-rw-r--r--  2.0 unx     2946 b- defN 24-Mar-27 14:23 finter/settings.py
 -rw-r--r--  2.0 unx       39 b- defN 24-Feb-25 07:38 finter/ai/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-25 07:38 finter/ai/gpt/__init__.py
 -rw-r--r--  2.0 unx      335 b- defN 24-Mar-09 04:02 finter/ai/gpt/chat.py
+-rw-r--r--  2.0 unx      500 b- defN 24-Apr-10 08:18 finter/ai/gpt/cm_docs.py
 -rw-r--r--  2.0 unx       39 b- defN 24-Mar-09 04:02 finter/ai/gpt/config.py
--rw-r--r--  2.0 unx      618 b- defN 24-Mar-13 03:21 finter/ai/gpt/cookbook.py
--rw-r--r--  2.0 unx      661 b- defN 24-Mar-09 04:02 finter/ai/gpt/release_note.py
--rw-r--r--  2.0 unx      619 b- defN 24-Feb-19 14:06 finter/api/__init__.py
+-rw-r--r--  2.0 unx      611 b- defN 24-Mar-15 13:27 finter/ai/gpt/cookbook.py
+-rw-r--r--  2.0 unx     1138 b- defN 24-Apr-08 22:55 finter/ai/gpt/release_note.py
+-rw-r--r--  2.0 unx       60 b- defN 24-Mar-22 06:21 finter/ai/quanda_bot/__init__.py
+-rw-r--r--  2.0 unx     2271 b- defN 24-Mar-26 08:53 finter/ai/quanda_bot/generate.py
+-rw-r--r--  2.0 unx      680 b- defN 24-Apr-08 00:23 finter/api/__init__.py
 -rw-r--r--  2.0 unx    19412 b- defN 24-Feb-19 14:06 finter/api/alpha_api.py
+-rw-r--r--  2.0 unx     4177 b- defN 24-Apr-08 00:23 finter/api/aws_credentials_api.py
 -rw-r--r--  2.0 unx    11068 b- defN 24-Mar-08 01:36 finter/api/calendar_api.py
 -rw-r--r--  2.0 unx    14436 b- defN 24-Feb-19 14:06 finter/api/content_api.py
 -rw-r--r--  2.0 unx    19582 b- defN 24-Feb-19 14:06 finter/api/default_api.py
 -rw-r--r--  2.0 unx    11384 b- defN 24-Feb-19 14:06 finter/api/flexible_fund_api.py
 -rw-r--r--  2.0 unx    11088 b- defN 24-Feb-19 14:06 finter/api/fund_api.py
 -rw-r--r--  2.0 unx    12002 b- defN 24-Feb-19 14:06 finter/api/metafund_api.py
 -rw-r--r--  2.0 unx     7040 b- defN 24-Feb-19 14:06 finter/api/performance_api.py
 -rw-r--r--  2.0 unx    18410 b- defN 24-Feb-19 14:06 finter/api/portfolio_api.py
 -rw-r--r--  2.0 unx     4523 b- defN 24-Mar-07 02:23 finter/api/quanda_bot_api.py
+-rw-r--r--  2.0 unx     7663 b- defN 24-Mar-27 14:23 finter/api/quanda_data_api.py
 -rw-r--r--  2.0 unx     4810 b- defN 24-Feb-19 14:06 finter/api/simulation_api.py
--rw-r--r--  2.0 unx     4281 b- defN 24-Feb-19 14:06 finter/api/sm_api.py
--rw-r--r--  2.0 unx     6508 b- defN 24-Feb-19 14:06 finter/api/submission_api.py
+-rw-r--r--  2.0 unx     4482 b- defN 24-Mar-19 01:43 finter/api/sm_api.py
+-rw-r--r--  2.0 unx     6716 b- defN 24-Apr-09 09:13 finter/api/submission_api.py
 -rw-r--r--  2.0 unx     6777 b- defN 24-Feb-19 14:06 finter/api/universe_api.py
--rw-r--r--  2.0 unx       38 b- defN 24-Mar-08 01:48 finter/data/__init__.py
--rw-r--r--  2.0 unx     3766 b- defN 24-Mar-08 01:48 finter/data/load.py
--rw-r--r--  2.0 unx      632 b- defN 24-Mar-08 01:36 finter/framework_model/__init__.py
+-rw-r--r--  2.0 unx     6084 b- defN 24-Mar-18 18:19 finter/api/user_api.py
+-rw-r--r--  2.0 unx      105 b- defN 24-Mar-18 01:38 finter/calendar/__init__.py
+-rw-r--r--  2.0 unx       98 b- defN 24-Apr-01 13:27 finter/data/__init__.py
+-rw-r--r--  2.0 unx     5936 b- defN 24-Apr-12 08:32 finter/data/load.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-01 13:31 finter/data/content_model/__init__.py
+-rw-r--r--  2.0 unx      275 b- defN 24-Apr-08 03:23 finter/data/content_model/catalog_sheet.py
+-rw-r--r--  2.0 unx     5134 b- defN 24-Apr-12 08:32 finter/data/content_model/loader.py
+-rw-r--r--  2.0 unx      570 b- defN 24-Apr-01 13:27 finter/framework_model/__init__.py
 -rw-r--r--  2.0 unx      529 b- defN 24-Feb-19 14:06 finter/framework_model/alpha.py
 -rw-r--r--  2.0 unx     1466 b- defN 24-Mar-04 04:00 finter/framework_model/alpha_loader.py
+-rw-r--r--  2.0 unx     1198 b- defN 24-Apr-09 09:11 finter/framework_model/aws_credentials.py
 -rw-r--r--  2.0 unx     4994 b- defN 24-Mar-08 01:36 finter/framework_model/calendar.py
 -rw-r--r--  2.0 unx     1184 b- defN 24-Mar-04 04:00 finter/framework_model/cm_loader.py
 -rw-r--r--  2.0 unx      902 b- defN 24-Feb-19 14:06 finter/framework_model/portfolio.py
--rw-r--r--  2.0 unx      707 b- defN 24-Mar-13 03:53 finter/framework_model/simulation.py
+-rw-r--r--  2.0 unx      796 b- defN 24-Mar-16 13:35 finter/framework_model/simulation.py
 -rw-r--r--  2.0 unx      788 b- defN 24-Mar-04 04:00 finter/framework_model/universe.py
--rw-r--r--  2.0 unx     7012 b- defN 24-Mar-13 03:53 finter/framework_model/validation.py
+-rw-r--r--  2.0 unx     7224 b- defN 24-Mar-16 13:33 finter/framework_model/validation.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-20 00:55 finter/framework_model/submission/__init__.py
--rw-r--r--  2.0 unx     1097 b- defN 24-Mar-02 12:35 finter/framework_model/submission/config.py
+-rw-r--r--  2.0 unx     2946 b- defN 24-Mar-25 02:58 finter/framework_model/submission/config.py
 -rw-r--r--  2.0 unx     3500 b- defN 24-Mar-11 23:14 finter/framework_model/submission/helper_github.py
 -rw-r--r--  2.0 unx      218 b- defN 24-Mar-11 22:55 finter/framework_model/submission/helper_github_config.py
--rw-r--r--  2.0 unx     2815 b- defN 24-Mar-02 12:35 finter/framework_model/submission/helper_notebook.py
+-rw-r--r--  2.0 unx     3063 b- defN 24-Mar-20 00:40 finter/framework_model/submission/helper_notebook.py
 -rw-r--r--  2.0 unx     2036 b- defN 24-Mar-02 12:35 finter/framework_model/submission/helper_position.py
--rw-r--r--  2.0 unx     2979 b- defN 24-Mar-02 12:35 finter/framework_model/submission/helper_simulation.py
+-rw-r--r--  2.0 unx    12428 b- defN 24-Apr-12 08:52 finter/framework_model/submission/helper_simulation.py
 -rw-r--r--  2.0 unx      664 b- defN 24-Mar-04 04:00 finter/framework_model/submission/helper_submission.py
--rw-r--r--  2.0 unx     6423 b- defN 24-Mar-11 22:55 finter/framework_model/submission/notebook.py
--rw-r--r--  2.0 unx     3022 b- defN 24-Mar-08 01:36 finter/models/__init__.py
+-rw-r--r--  2.0 unx     9780 b- defN 24-Apr-12 08:32 finter/framework_model/submission/notebook.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-11 11:57 finter/modeling/__init__.py
+-rw-r--r--  2.0 unx     2001 b- defN 24-Apr-11 11:57 finter/modeling/calendar.py
+-rw-r--r--  2.0 unx     3096 b- defN 24-Apr-08 00:23 finter/models/__init__.py
 -rw-r--r--  2.0 unx     3122 b- defN 24-Feb-19 14:06 finter/models/all_of_content_data_response_valid_data_graph.py
 -rw-r--r--  2.0 unx     3219 b- defN 24-Feb-19 14:06 finter/models/all_of_metafund_performance_response_threeyears.py
 -rw-r--r--  2.0 unx     4630 b- defN 24-Feb-19 14:06 finter/models/alpha.py
 -rw-r--r--  2.0 unx     9841 b- defN 24-Feb-19 14:06 finter/models/alpha_fields.py
 -rw-r--r--  2.0 unx     4754 b- defN 24-Feb-19 14:06 finter/models/alpha_identities_response.py
 -rw-r--r--  2.0 unx     4976 b- defN 24-Feb-19 14:06 finter/models/alpha_model_response.py
 -rw-r--r--  2.0 unx     5379 b- defN 24-Feb-19 14:06 finter/models/alpha_search_response.py
 -rw-r--r--  2.0 unx     8384 b- defN 24-Feb-19 14:06 finter/models/alpha_simulation_request.py
 -rw-r--r--  2.0 unx     7118 b- defN 24-Feb-19 14:06 finter/models/alpha_simulation_response.py
 -rw-r--r--  2.0 unx     6325 b- defN 24-Feb-19 14:06 finter/models/ap_position.py
+-rw-r--r--  2.0 unx     5760 b- defN 24-Apr-08 00:23 finter/models/aws_credentials_response.py
 -rw-r--r--  2.0 unx     6048 b- defN 24-Feb-19 14:06 finter/models/base_alpha_content_model_response.py
 -rw-r--r--  2.0 unx     9917 b- defN 24-Feb-19 14:06 finter/models/base_portfolio_get_alpha.py
 -rw-r--r--  2.0 unx     6006 b- defN 24-Feb-19 14:06 finter/models/base_portfolio_model_response.py
 -rw-r--r--  2.0 unx     5787 b- defN 24-Feb-19 14:06 finter/models/calendar_response.py
+-rw-r--r--  2.0 unx     4436 b- defN 24-Mar-18 18:02 finter/models/code_response.py
 -rw-r--r--  2.0 unx     4668 b- defN 24-Feb-19 14:06 finter/models/content.py
 -rw-r--r--  2.0 unx     4421 b- defN 24-Feb-19 14:06 finter/models/content_category_response.py
 -rw-r--r--  2.0 unx     4130 b- defN 24-Feb-19 14:06 finter/models/content_data.py
 -rw-r--r--  2.0 unx     3614 b- defN 24-Feb-19 14:06 finter/models/content_data_request.py
 -rw-r--r--  2.0 unx     6505 b- defN 24-Feb-19 14:06 finter/models/content_data_response.py
 -rw-r--r--  2.0 unx     6910 b- defN 24-Feb-19 14:06 finter/models/content_fields.py
 -rw-r--r--  2.0 unx     4766 b- defN 24-Feb-19 14:06 finter/models/content_identites_response.py
@@ -97,36 +112,36 @@
 -rw-r--r--  2.0 unx     4706 b- defN 24-Feb-19 14:06 finter/models/portfolio.py
 -rw-r--r--  2.0 unx     9345 b- defN 24-Feb-19 14:06 finter/models/portfolio_fields.py
 -rw-r--r--  2.0 unx     4802 b- defN 24-Feb-19 14:06 finter/models/portfolio_identities_response.py
 -rw-r--r--  2.0 unx     5040 b- defN 24-Feb-19 14:06 finter/models/portfolio_model_response.py
 -rw-r--r--  2.0 unx     5623 b- defN 24-Feb-19 14:06 finter/models/portfolio_search_response.py
 -rw-r--r--  2.0 unx     8528 b- defN 24-Feb-19 14:06 finter/models/portfolio_simulation_request.py
 -rw-r--r--  2.0 unx     6983 b- defN 24-Feb-19 14:06 finter/models/portfolio_simulation_response.py
--rw-r--r--  2.0 unx    16911 b- defN 24-Feb-19 14:06 finter/models/simulation_request.py
+-rw-r--r--  2.0 unx    17786 b- defN 24-Mar-25 03:01 finter/models/simulation_request.py
 -rw-r--r--  2.0 unx     4403 b- defN 24-Feb-19 14:06 finter/models/simulation_response.py
 -rw-r--r--  2.0 unx     4370 b- defN 24-Feb-19 14:06 finter/models/submission_request.py
 -rw-r--r--  2.0 unx     4403 b- defN 24-Feb-19 14:06 finter/models/submission_response.py
 -rw-r--r--  2.0 unx     8538 b- defN 24-Feb-19 14:06 finter/models/table_data.py
 -rw-r--r--  2.0 unx     5791 b- defN 24-Mar-08 01:36 finter/models/trading_day_response.py
 -rw-r--r--  2.0 unx     4376 b- defN 24-Feb-19 14:06 finter/models/universe_response.py
 -rw-r--r--  2.0 unx     4253 b- defN 24-Feb-19 14:06 finter/models/user_login_request.py
 -rw-r--r--  2.0 unx     3438 b- defN 24-Feb-19 14:06 finter/models/user_login_response.py
 -rw-r--r--  2.0 unx     3525 b- defN 24-Feb-19 14:06 finter/models/wm_performance_request.py
 -rw-r--r--  2.0 unx     4409 b- defN 24-Feb-19 14:06 finter/models/wmap_performance_request.py
 -rw-r--r--  2.0 unx     5029 b- defN 24-Feb-19 14:06 finter/models/wmap_return_request.py
 -rw-r--r--  2.0 unx     4340 b- defN 24-Feb-19 14:06 finter/models/wmap_return_response.py
--rw-r--r--  2.0 unx       91 b- defN 24-Feb-19 14:06 finter/utils/__init__.py
+-rw-r--r--  2.0 unx      106 b- defN 24-Apr-11 11:57 finter/utils/__init__.py
 -rw-r--r--  2.0 unx     1841 b- defN 24-Mar-08 01:36 finter/utils/convert.py
--rw-r--r--  2.0 unx      283 b- defN 24-Feb-19 14:06 finter/utils/func_utils.py
+-rw-r--r--  2.0 unx     1560 b- defN 24-Mar-16 14:08 finter/utils/func_utils.py
 -rw-r--r--  2.0 unx      317 b- defN 24-Feb-19 14:06 finter/utils/index.py
 -rw-r--r--  2.0 unx      543 b- defN 24-Mar-02 12:35 finter/utils/timer.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-19 14:06 finter/utils/library/__init__.py
 -rw-r--r--  2.0 unx     1415 b- defN 24-Feb-19 14:06 finter/utils/library/context.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-19 14:06 finter/utils/model/__init__.py
 -rw-r--r--  2.0 unx     1079 b- defN 24-Feb-19 14:06 finter/utils/model/frames.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Mar-08 13:29 finter/utils/testing/__init__.py
 -rw-r--r--  2.0 unx      302 b- defN 24-Mar-08 01:36 finter/utils/testing/format.py
--rw-r--r--  2.0 unx     4107 b- defN 24-Mar-13 03:54 finter-0.1.9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-13 03:54 finter-0.1.9.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 24-Mar-13 03:54 finter-0.1.9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    11741 b- defN 24-Mar-13 03:54 finter-0.1.9.dist-info/RECORD
-130 files, 683154 bytes uncompressed, 168030 bytes compressed:  75.4%
+-rw-r--r--  2.0 unx     6557 b- defN 24-Apr-15 05:32 finter-0.2.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-15 05:32 finter-0.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 24-Apr-15 05:32 finter-0.2.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    13069 b- defN 24-Apr-15 05:32 finter-0.2.0.dist-info/RECORD
+145 files, 748983 bytes uncompressed, 186670 bytes compressed:  75.1%
```

## zipnote {}

```diff
@@ -18,29 +18,41 @@
 
 Filename: finter/ai/gpt/__init__.py
 Comment: 
 
 Filename: finter/ai/gpt/chat.py
 Comment: 
 
+Filename: finter/ai/gpt/cm_docs.py
+Comment: 
+
 Filename: finter/ai/gpt/config.py
 Comment: 
 
 Filename: finter/ai/gpt/cookbook.py
 Comment: 
 
 Filename: finter/ai/gpt/release_note.py
 Comment: 
 
+Filename: finter/ai/quanda_bot/__init__.py
+Comment: 
+
+Filename: finter/ai/quanda_bot/generate.py
+Comment: 
+
 Filename: finter/api/__init__.py
 Comment: 
 
 Filename: finter/api/alpha_api.py
 Comment: 
 
+Filename: finter/api/aws_credentials_api.py
+Comment: 
+
 Filename: finter/api/calendar_api.py
 Comment: 
 
 Filename: finter/api/content_api.py
 Comment: 
 
 Filename: finter/api/default_api.py
@@ -60,41 +72,62 @@
 
 Filename: finter/api/portfolio_api.py
 Comment: 
 
 Filename: finter/api/quanda_bot_api.py
 Comment: 
 
+Filename: finter/api/quanda_data_api.py
+Comment: 
+
 Filename: finter/api/simulation_api.py
 Comment: 
 
 Filename: finter/api/sm_api.py
 Comment: 
 
 Filename: finter/api/submission_api.py
 Comment: 
 
 Filename: finter/api/universe_api.py
 Comment: 
 
+Filename: finter/api/user_api.py
+Comment: 
+
+Filename: finter/calendar/__init__.py
+Comment: 
+
 Filename: finter/data/__init__.py
 Comment: 
 
 Filename: finter/data/load.py
 Comment: 
 
+Filename: finter/data/content_model/__init__.py
+Comment: 
+
+Filename: finter/data/content_model/catalog_sheet.py
+Comment: 
+
+Filename: finter/data/content_model/loader.py
+Comment: 
+
 Filename: finter/framework_model/__init__.py
 Comment: 
 
 Filename: finter/framework_model/alpha.py
 Comment: 
 
 Filename: finter/framework_model/alpha_loader.py
 Comment: 
 
+Filename: finter/framework_model/aws_credentials.py
+Comment: 
+
 Filename: finter/framework_model/calendar.py
 Comment: 
 
 Filename: finter/framework_model/cm_loader.py
 Comment: 
 
 Filename: finter/framework_model/portfolio.py
@@ -132,14 +165,20 @@
 
 Filename: finter/framework_model/submission/helper_submission.py
 Comment: 
 
 Filename: finter/framework_model/submission/notebook.py
 Comment: 
 
+Filename: finter/modeling/__init__.py
+Comment: 
+
+Filename: finter/modeling/calendar.py
+Comment: 
+
 Filename: finter/models/__init__.py
 Comment: 
 
 Filename: finter/models/all_of_content_data_response_valid_data_graph.py
 Comment: 
 
 Filename: finter/models/all_of_metafund_performance_response_threeyears.py
@@ -165,26 +204,32 @@
 
 Filename: finter/models/alpha_simulation_response.py
 Comment: 
 
 Filename: finter/models/ap_position.py
 Comment: 
 
+Filename: finter/models/aws_credentials_response.py
+Comment: 
+
 Filename: finter/models/base_alpha_content_model_response.py
 Comment: 
 
 Filename: finter/models/base_portfolio_get_alpha.py
 Comment: 
 
 Filename: finter/models/base_portfolio_model_response.py
 Comment: 
 
 Filename: finter/models/calendar_response.py
 Comment: 
 
+Filename: finter/models/code_response.py
+Comment: 
+
 Filename: finter/models/content.py
 Comment: 
 
 Filename: finter/models/content_category_response.py
 Comment: 
 
 Filename: finter/models/content_data.py
@@ -372,20 +417,20 @@
 
 Filename: finter/utils/testing/__init__.py
 Comment: 
 
 Filename: finter/utils/testing/format.py
 Comment: 
 
-Filename: finter-0.1.9.dist-info/METADATA
+Filename: finter-0.2.0.dist-info/METADATA
 Comment: 
 
-Filename: finter-0.1.9.dist-info/WHEEL
+Filename: finter-0.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: finter-0.1.9.dist-info/top_level.txt
+Filename: finter-0.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: finter-0.1.9.dist-info/RECORD
+Filename: finter-0.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## finter/__init__.py

```diff
@@ -19,14 +19,15 @@
 except ImportError:
     # Python<3.8 compatibility
     from importlib_metadata import version
 
 __version__ = version("finter")
 
 # import apis into sdk package
+from finter.api.aws_credentials_api import AWSCredentialsApi
 from finter.api.alpha_api import AlphaApi
 from finter.api.content_api import ContentApi
 from finter.api.flexible_fund_api import FlexibleFundApi
 from finter.api.fund_api import FundApi
 from finter.api.metafund_api import MetafundApi
 from finter.api.portfolio_api import PortfolioApi
 from finter.api.default_api import DefaultApi
@@ -38,14 +39,15 @@
 from finter.api_client import ApiClient
 from finter.configuration import Configuration
 # import models into sdk package
 from finter.models.all_of_content_data_response_valid_data_graph import AllOfContentDataResponseValidDataGraph
 from finter.models.all_of_metafund_performance_response_threeyears import AllOfMetafundPerformanceResponseThreeyears
 from finter.models.alpha_identities_response import AlphaIdentitiesResponse
 from finter.models.alpha_model_response import AlphaModelResponse
+from finter.models.aws_credentials_response import AwsCredentialsResponse
 from finter.models.content_category_response import ContentCategoryResponse
 from finter.models.content_data_request import ContentDataRequest
 from finter.models.content_data_response import ContentDataResponse
 from finter.models.content_identites_response import ContentIdentitesResponse
 from finter.models.content_model_response import ContentModelResponse
 from finter.models.flexible_fund_identities_response import FlexibleFundIdentitiesResponse
 from finter.models.flexible_fund_model_response import FlexibleFundModelResponse
@@ -69,7 +71,13 @@
 from finter.models.simulation_response import SimulationResponse
 
 from finter.api.submission_api import SubmissionApi
 from finter.models.submission_request import SubmissionRequest
 from finter.models.submission_response import SubmissionResponse
 
 from finter.utils.convert import to_dataframe
+
+# framework
+from finter.framework_model import BaseAlpha, BasePortfolio
+from finter.framework_model.submission.notebook import NotebookSubmissionHelper
+from finter.framework_model.submission.helper_simulation import Simulation
+from finter.framework_model.aws_credentials import get_parquet_df
```

## finter/settings.py

```diff
@@ -1,15 +1,28 @@
+import hashlib
 import logging
 import traceback
+import uuid
 
 import finter
 from dotenv import load_dotenv
+from finter.api.user_api import UserApi
+from finter.rest import ApiException
 
 load_dotenv()
 
+logger = logging.getLogger("finter_sdk")
+logger.setLevel(logging.INFO)
+
+log_handler = logging.StreamHandler()
+log_handler.setLevel(logging.INFO)  # 필요한 로깅 레벨 설정
+logger.addHandler(log_handler)
+formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+log_handler.setFormatter(formatter)
+
 
 def check_configuration():
     configuration = finter.Configuration()
     if configuration.api_key["Authorization"] == "Token None":
         error_message = (
             "API Key is not set. Please set the API Key to proceed.\n\n"
             "You can set the API Key in one of the following ways:\n"
@@ -35,20 +48,55 @@
     separator = "=" * 40
     header = f"\n{separator} {title} {separator}"
     logger.info(header)
 
     log_handler.setFormatter(original_formatter)
 
 
+def log_warning(message):
+    original_formatter = log_handler.formatter
+
+    log_handler.setFormatter(logging.Formatter("%(message)s"))
+
+    logger.warning(message)
+
+    log_handler.setFormatter(original_formatter)
+
+
+def log_with_user_event(
+    event_message, source, method, category, log_type=None, log_message=None
+):
+    if log_message:
+        if log_type == "error":
+            logger.error(log_message)
+        elif log_type == "warning":
+            logger.warning(log_message)
+        elif log_type == "info":
+            logger.info(log_message)
+        else:
+            pass
+    user_event(event_message, source=source, method=method, category=category)
+
+
 def log_with_traceback(message):
     logger.error(message)
     logger.error(traceback.format_exc())
 
 
-logger = logging.getLogger("finter_sdk")
-logger.setLevel(logging.INFO)
-
-log_handler = logging.StreamHandler()
-log_handler.setLevel(logging.INFO)  # 필요한 로깅 레벨 설정
-logger.addHandler(log_handler)
-formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
-log_handler.setFormatter(formatter)
+def user_event(name, source="", method="", category=""):
+    def _random_hash():
+        random_uuid = uuid.uuid4()
+        uuid_bytes = str(random_uuid).encode()
+        hash_object = hashlib.sha256(uuid_bytes)
+        return hash_object.hexdigest()
+
+    params = {
+        "name": name,
+        "source": source,
+        "method": method,
+        "category": category,
+        "rand": _random_hash(),
+    }
+    try:
+        UserApi().log_usage_retrieve(**params)
+    except ApiException as e:
+        logger.error("Exception when calling UserApi->log_usage_retrieve: %s\n" % e)
```

## finter/ai/gpt/cookbook.py

```diff
@@ -1,25 +1,26 @@
 import sys
 
 import requests
+
 from finter.ai.gpt.config import URL_NAME
 
 
 def get_file_content(file_path):
     with open(file_path, "r", encoding="utf-8") as file:
         file_content = file.read()
     return file_content
 
 
-def generate_release_note(file_path=""):
+def generate_cookbook(file_path=""):
     url = f"http://{URL_NAME}:8282/cookbook"
     input_text = get_file_content(file_path)
 
     data = {"input": input_text}
     response = requests.post(url, json=data)
     return response.json()["result"]
 
 
 if __name__ == "__main__":
     user_prompt = sys.argv[1] if len(sys.argv) > 1 else ""
-    rel = generate_release_note(user_prompt)
+    rel = generate_cookbook(user_prompt)
     print(rel)
```

## finter/ai/gpt/release_note.py

```diff
@@ -1,14 +1,27 @@
 import os
 import sys
 
 import requests
+
 from finter.ai.gpt.config import URL_NAME
 
 
+def send_slack_message(webhook_url, message):
+    formatted_message = f"```{message}```"
+    headers = {"Content-Type": "application/json"}
+    data = {
+        "blocks": [
+            {"type": "section", "text": {"type": "mrkdwn", "text": formatted_message}}
+        ]
+    }
+    response = requests.post(webhook_url, headers=headers, json=data)
+    return response.text
+
+
 def get_logs():
     diff_script_path = os.path.join(os.path.dirname(__file__), "tag_diff_logs.sh")
     with os.popen(f"bash {diff_script_path}") as p:
         output = p.read()
     return output
 
 
@@ -19,7 +32,10 @@
     return response.json()["result"]
 
 
 if __name__ == "__main__":
     user_prompt = sys.argv[1] if len(sys.argv) > 1 else ""
     rel = generate_release_note(user_prompt)
     print(rel)
+
+    slack_webhook_url = os.getenv("SLACK_WEBHOOK_URL")
+    send_slack_message(slack_webhook_url, rel)
```

## finter/api/__init__.py

```diff
@@ -1,12 +1,13 @@
 from __future__ import absolute_import
 
 # flake8: noqa
 
 # import apis into api package
+from finter.api.aws_credentials_api import AWSCredentialsApi
 from finter.api.alpha_api import AlphaApi
 from finter.api.content_api import ContentApi
 from finter.api.flexible_fund_api import FlexibleFundApi
 from finter.api.fund_api import FundApi
 from finter.api.metafund_api import MetafundApi
 from finter.api.portfolio_api import PortfolioApi
 from finter.api.default_api import DefaultApi
```

## finter/api/sm_api.py

```diff
@@ -37,14 +37,15 @@
 
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
         >>> thread = api.sm_data_retrieve(async_req=True)
         >>> result = thread.get()
 
         :param async_req bool
+        :param str bucket_name:
         :param str identity_name:
         :return: dict(str, object)
                  If the method is called asynchronously,
                  returns the request thread.
         """
         kwargs['_return_http_data_only'] = True
         if kwargs.get('async_req'):
@@ -58,21 +59,22 @@
 
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
         >>> thread = api.sm_data_retrieve_with_http_info(async_req=True)
         >>> result = thread.get()
 
         :param async_req bool
+        :param str bucket_name:
         :param str identity_name:
         :return: dict(str, object)
                  If the method is called asynchronously,
                  returns the request thread.
         """
 
-        all_params = ['identity_name']  # noqa: E501
+        all_params = ['bucket_name', 'identity_name']  # noqa: E501
         all_params.append('async_req')
         all_params.append('_return_http_data_only')
         all_params.append('_preload_content')
         all_params.append('_request_timeout')
 
         params = locals()
         for key, val in six.iteritems(params['kwargs']):
@@ -85,14 +87,16 @@
         del params['kwargs']
 
         collection_formats = {}
 
         path_params = {}
 
         query_params = []
+        if 'bucket_name' in params:
+            query_params.append(('bucket_name', params['bucket_name']))  # noqa: E501
         if 'identity_name' in params:
             query_params.append(('identity_name', params['identity_name']))  # noqa: E501
 
         header_params = {}
 
         form_params = []
         local_var_files = {}
```

## finter/api/submission_api.py

```diff
@@ -8,23 +8,24 @@
     OpenAPI spec version: 0.298
     
     Generated by: https://github.com/swagger-api/swagger-codegen.git
 """
 
 from __future__ import absolute_import
 
-import re  # noqa: F401
 import json
+import os
+import re  # noqa: F401
 import shutil
+import tempfile
+from datetime import datetime, timedelta
 
 # python 2 and python 3 compatibility library
 import six
 
-from datetime import datetime, timedelta
-
 from finter.api_client import ApiClient
 
 
 class SubmissionApi(object):
     """NOTE: This class is auto generated by the swagger code generator program.
 
     Do not edit the class manually.
@@ -50,39 +51,40 @@
         :param str model_dir: (required)
         :return: SubmissionResponse
                  If the method is called asynchronously,
                  returns the request thread.
         """
         kwargs['_return_http_data_only'] = True
 
-        # add metas to model info
-        if isinstance(model_info, str):  # convert json to dict
-            model_info = json.loads(model_info)
-        model_info['submission_time'] = str(datetime.now())
-        model_nickname = model_dir.split('/')[-1].split('.zip')[0]
-        model_info['nickname'] = model_nickname
-        model_info['model_dir'] = model_dir
-
-        # save model meta and zip model files
-        json.dump(model_info, open(f'{model_dir}/model_meta.json', 'w'), indent=4)
-        shutil.make_archive(f"{model_nickname}", "zip", model_dir)
-        model_zip_file = f"{model_nickname}.zip"
-
-        # remove unnecessary keys
-        del model_info['submission_time']
-        del model_info['model_dir']
-
-        # change model_info from dict to json for HTTP POST
-        model_info = json.dumps(model_info)
-
-        if kwargs.get('async_req'):
-            return self.submission_create_with_http_info(model_info, model_zip_file, **kwargs)  # noqa: E501
-        else:
-            (data) = self.submission_create_with_http_info(model_info, model_zip_file, **kwargs)  # noqa: E501
-            return data
+        with tempfile.TemporaryDirectory() as temp_dir:
+            # add metas to model info
+            if isinstance(model_info, str):  # convert json to dict
+                model_info = json.loads(model_info)
+            model_info['submission_time'] = str(datetime.now())
+            model_nickname = model_dir.split('/')[-1].split('.zip')[0]
+            model_info['nickname'] = model_nickname
+            model_info['model_dir'] = model_dir
+
+            # save model meta and zip model files
+            json.dump(model_info, open(f'{model_dir}/model_meta.json', 'w'), indent=4)
+            shutil.make_archive(os.path.join(temp_dir, model_nickname), "zip", model_dir)
+            model_zip_file = os.path.join(temp_dir, f"{model_nickname}.zip")
+
+            # remove unnecessary keys
+            del model_info['submission_time']
+            del model_info['model_dir']
+
+            # change model_info from dict to json for HTTP POST
+            model_info = json.dumps(model_info)
+
+            if kwargs.get('async_req'):
+                return self.submission_create_with_http_info(model_info, model_zip_file, **kwargs)  # noqa: E501
+            else:
+                (data) = self.submission_create_with_http_info(model_info, model_zip_file, **kwargs)  # noqa: E501
+                return data
 
     def submission_create_with_http_info(self, model_info, model_zip_file, **kwargs):  # noqa: E501
         """submission_create  # noqa: E501
 
         Finter submission  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
```

## finter/data/__init__.py

```diff
@@ -1 +1,2 @@
-from finter.data.load import ModelData
+from finter.data.load import ModelData
+from finter.data.content_model.loader import ContentFactory
```

## finter/data/load.py

```diff
@@ -5,16 +5,55 @@
 from finter.api.metafund_api import MetafundApi
 from finter.api.portfolio_api import PortfolioApi
 from finter.settings import get_api_client, logger
 from finter.utils.convert import to_dataframe
 
 
 class ModelData:
+    """
+    A class to handle the loading of various financial model data based on their identity names.
+
+    This class provides functionality to retrieve data for content models, alpha models, portfolio models, fund models, and flexible fund models. It raises errors for unsupported or unknown model types.
+
+    Methods:
+        load(identity_name: str) -> pd.DataFrame:
+            Determines the model type from the identity name and calls the appropriate method to retrieve and convert the model data into a DataFrame.
+        get_cm_df(identity_name: str) -> pd.DataFrame:
+            Retrieves content model data using the ContentApi and converts it to a DataFrame.
+        get_am_df(identity_name: str) -> pd.DataFrame:
+            Retrieves alpha model data using the AlphaApi and converts it to a DataFrame.
+        get_pm_df(identity_name: str) -> pd.DataFrame:
+            Retrieves portfolio model data using the PortfolioApi and converts it to a DataFrame.
+        get_fm_df(identity_name: str) -> pd.DataFrame:
+            Retrieves fund model data using the FundApi and converts it to a DataFrame.
+        get_ffm_df(identity_name: str) -> pd.DataFrame:
+            Retrieves flexible fund model data using the FlexibleFundApi and converts it to a DataFrame.
+
+    Raises:
+        NotImplementedError: If an attempt is made to load data for metafund models, which are not supported yet.
+        ValueError: If the model type is unknown.
+    """
+
     @classmethod
     def load(cls, identity_name: str):
+        """
+        Loads model data based on the provided identity name by determining the type of model
+        and calling the corresponding method to fetch and process the data.
+
+        Args:
+            identity_name (str): The identity name of the model, formatted as '<model_type>.<additional_info>'.
+                Example: 'alpha.krx.krx.stock.ldh0127.div_2'.
+
+        Returns:
+            pd.DataFrame: A DataFrame containing the loaded model data.
+
+        Raises:
+            NotImplementedError: If the model type is 'metafund', which is currently not supported.
+            ValueError: If the model type is unknown, indicating an unsupported or improperly formatted identity name.
+        """
         model_type = identity_name.split(".")[0]
         if model_type == "content":
             df = cls.get_cm_df(identity_name)
         elif model_type == "alpha":
             df = cls.get_am_df(identity_name)
         elif model_type == "portfolio":
             df = cls.get_pm_df(identity_name)
```

## finter/framework_model/__init__.py

```diff
@@ -1,11 +1,14 @@
 from finter.framework_model.cm_loader import ContentModelLoader
 from finter.framework_model.alpha import BaseAlpha
 from finter.framework_model.portfolio import BasePortfolio
 from finter.framework_model.alpha_loader import AlphaPositionLoader
 from finter.framework_model.simulation import adj_stat_container_helper
 from finter.framework_model.calendar import (
-    iter_trading_days, iter_holidays, iter_days, TradingDay, Code
+    iter_trading_days,
+    iter_holidays,
+    iter_days,
+    TradingDay,
+    Code,
 )
 from finter.framework_model.universe import get_universe_list
 from finter.framework_model.validation import ValidationHelper
-from finter.framework_model.submission.notebook import NotebookSubmissionHelper
```

## finter/framework_model/simulation.py

```diff
@@ -1,18 +1,21 @@
 from __future__ import print_function
 
 import finter
 from finter.settings import get_api_client
 from finter.rest import ApiException
+from finter.utils import with_spinner
 from finter.utils.convert import get_json_with_columns_from_dataframe
 
 
+@with_spinner(text="Waiting Simulation result...")
 def adj_stat_container_helper(**kwargs):
     if 'position' in kwargs:
         kwargs['position'], kwargs['position_column_types'] = get_json_with_columns_from_dataframe(kwargs['position'])
+
     body = finter.SimulationRequest(**kwargs)  # SimulationRequest |
 
     try:
         api_response = finter.SimulationApi(get_api_client()).simulation_create(body)
         return api_response.result
     except ApiException as e:
-        print("Exception when calling SimulationApi->simulation_create: %s\n" % e)
+        print("Exception when calling SimulationApi->simulation_create: %s\n" % e)
```

## finter/framework_model/validation.py

```diff
@@ -1,22 +1,29 @@
+import warnings
+warnings.filterwarnings(action='ignore')  # for clean logging, warning is not working on validation
+
 import os.path
 import re
+
 from abc import ABCMeta, abstractmethod
 from datetime import datetime, timedelta
 from pathlib import Path
 
-import pandas as pd
+from finter.utils import with_spinner
 
 from finter.framework_model.calendar import iter_days
 from finter.settings import logger
 from finter.utils.index import outsample_end_date
 from finter.utils.library.context import LibraryContext
 from finter.utils.model.frames import FrameUtil
 from finter.utils.timer import timer
 
+import pandas as pd
+
+
 REVISION_PATTERN = [
     r".*\.rolling\(.{1,20}\)\.sum\(\)",
     r".*\.rolling\(.{1,20}\)\.std\(\)",
     r".*\.rolling\(.{1,20}\)\.mean\(\)",
     r".*\.resample\(.{1,20}\)\.sum\(\)",
     r".*\.resample\(.{1,20}\)\.std\(\)",
     r".*\.resample\(.{1,20}\)\.mean\(\)",
@@ -108,49 +115,53 @@
         assert ValidationHelper.validate_cm_loading(
             module_file, self.__MODEL_INFO["type"]
         ), "invalid cm loading please use 'Base[Alpha|Portfolio|Fund|FlexibleFund].get_cm' or 'self.get_cm'"
 
         self.validate_start_dependency()
         self.validate_end_dependency()
 
+    @with_spinner(
+        text='[Validation - start dependency] Processing...',
+        msg_success='[Validation - start dependency] Completed!',
+    )
     def validate_start_dependency(self):
-        logger.info("[Start] Start dependency validation")
         exchange = self.__MODEL_INFO["exchange"]
 
         def _getter(_end: datetime, _bef: int) -> pd.DataFrame:
             return self.__MODEL.get(
                 self.days_before(_end, _bef, exchange), int(_end.strftime("%Y%m%d"))
             )
 
         orig = _getter(self.end, 1)
         variation = _getter(self.end, 20)
         variation2 = _getter(self.end, 100)
 
         assert_index_share(orig, variation)
         assert_max_dependency(orig, variation, "start")
         assert_max_dependency(variation2, variation, "start")
-        logger.info("[END] Start dependency validation Succeeded")
 
+    @with_spinner(
+        text='[Validation - end dependency] Processing...',
+        msg_success='[Validation - end dependency] Completed!',
+    )
     def validate_end_dependency(self):
-        logger.info("[Start] End dependency validation")
         exchange = self.__MODEL_INFO["exchange"]
 
         def _getter(_end: datetime, _bef: int) -> pd.DataFrame:
             return self.__MODEL.get(
                 self.days_before(_end, 100, exchange),
                 self.days_before(_end, _bef, exchange),
             )
 
         orig = _getter(self.end, 0)
 
         for i in range(1, 64, 6):
             variation = _getter(self.end, i)
             assert_index_share(orig, variation)
             assert_max_dependency(orig, variation, "end")
-        logger.info("[END] End dependency validation Succeeded")
 
     @staticmethod
     def validate_code(path: str, model="") -> bool:
         with open(path, "r", encoding="utf-8") as f:
             return _validate_patterns(f.read(), REVISION_PATTERN + SLOW_PATTERN)
 
     @staticmethod
```

## finter/framework_model/submission/config.py

```diff
@@ -1,8 +1,10 @@
-from enum import Enum, auto
+from enum import Enum
+
+from finter.data import ModelData
 
 
 class ModelTypeConfig(Enum):
     ALPHA = {"class_name": "Alpha", "file_name": "am.py"}
     PORTFOLIO = {"class_name": "Portfolio", "file_name": "pf.py"}
 
     @property
@@ -14,16 +16,29 @@
         return self.value["file_name"]
 
     @classmethod
     def available_options(cls):
         return ", ".join([item.name for item in cls])
 
 
+class DefaultBenchmark(Enum):
+    KOSPI = "KOSPI"
+    KOSDAQ = "KOSDAQ"
+
+    @classmethod
+    def available_options(cls):
+        return [item.name for item in cls]
+
+    def get_benchmark_df(self):
+        df = ModelData.load("content.fnguide.ftp.economy.index_close.1d")
+        return df[self.value]
+
+
 class ModelUniverseConfig(Enum):
-    KR_STOCK = auto()
+    KR_STOCK = {"benchmark": DefaultBenchmark.KOSPI.value}
 
     def get_config(self, model_type: ModelTypeConfig):
         if self == ModelUniverseConfig.KR_STOCK:
             return {
                 "exchange": "krx",
                 "universe": "krx",
                 "instrument_type": "stock",
@@ -31,10 +46,57 @@
                 "position_type": "target",
                 "type": model_type.name.lower(),
                 "exposure": "long_only",
             }
         else:
             raise ValueError(f"Unknown universe: {self}")
 
+    def get_benchmark_config(self, benchmark):
+        if benchmark is None:
+            return self.value["benchmark"]
+        else:
+            return benchmark
+
     @classmethod
     def available_options(cls):
         return ", ".join([item.name for item in cls])
+
+
+def get_model_info(model_universe, model_type):
+    try:
+        model_info = ModelUniverseConfig[model_universe.upper()].get_config(
+            model_type=ModelTypeConfig[model_type.upper()]
+        )
+    except KeyError:
+        raise ValueError(
+            f"Invalid model universe: {model_universe}. Available options: {ModelUniverseConfig.available_options()}"
+        )
+
+    return model_info
+
+
+def validate_and_get_model_type_name(model_type):
+    try:
+        model_type = ModelTypeConfig[model_type.upper()].name
+    except KeyError:
+        raise ValueError(
+            f"Invalid model type: {model_type}. Available options: {ModelTypeConfig.available_options()}"
+        )
+
+    return model_type
+
+
+def validate_and_get_benchmark_name(model_universe, benchmark):
+    try:
+        benchmark = ModelUniverseConfig[model_universe.upper()].get_benchmark_config(
+            benchmark=benchmark
+        )
+        assert benchmark in DefaultBenchmark.available_options() + [False], (
+            f"Invalid benchmark: {benchmark}. Available options: "
+            f"{DefaultBenchmark.available_options()}, False"
+        )
+    except KeyError:
+        raise ValueError(
+            f"Invalid benchmark: {benchmark}. Available options: {DefaultBenchmark.available_options()}"
+        )
+
+    return benchmark
```

## finter/framework_model/submission/helper_notebook.py

```diff
@@ -1,26 +1,22 @@
 import os
 
 import nbformat
-from nbconvert import ScriptExporter
-
 from finter.framework_model.submission.config import ModelTypeConfig
 from finter.settings import logger
 from finter.utils.timer import timer
+from nbconvert import ScriptExporter
 
 
 @timer
-def extract_and_convert_notebook(
-    cell_indices, current_notebook_name, model_name, model_type="alpha"
-):
+def extract_and_convert_notebook(current_notebook_name, model_name, model_type="alpha"):
     """
-    Extracts specific cells from a notebook and converts them into a Python script.
+    Extracts specific cells containing a given class name from a notebook and converts them into a Python script.
 
     Parameters:
-    - cell_indices (list of int): Indices of the notebook cells to extract.
     - current_notebook_name (str): Name of the current notebook file (without .ipynb extension).
     - model_name (str): Directory to save the converted Python script.
     - model_type (str): Type of model (alpha or portfolio).
 
     Returns:
     - output_path (str): Path to the converted script if successful, False otherwise.
     """
@@ -28,17 +24,15 @@
     current_directory = os.getcwd()
 
     notebook_path = f"{current_notebook_name}.ipynb"
     output_path = os.path.join(
         model_name, ModelTypeConfig[model_type.upper()].file_name
     )
 
-    # Ensure cell_indices is a list
-    if isinstance(cell_indices, int):
-        cell_indices = [cell_indices]
+    class_declaration = f"class {ModelTypeConfig[model_type.upper()].class_name}"
 
     # Log directory
     logger.info(f"Current directory: {current_directory}")
     logger.info(f"Notebook path: {notebook_path}")
     logger.info(f"Output path: {output_path}")
 
     # Ensure the output directory exists
@@ -48,20 +42,30 @@
     try:
         with open(notebook_path, "r", encoding="utf-8") as notebook_file:
             notebook = nbformat.read(notebook_file, as_version=4)
     except IOError:
         logger.error(f"Error: Could not find {current_directory}/{notebook_path}")
         raise
 
-    # Extract specified cells
+    # Extract cells that contain the class_name
     try:
+        extracted_cells = [
+            cell for cell in notebook.cells if class_declaration in cell.source
+        ]
+
+        if not extracted_cells:
+            logger.error(
+                f"No cells containing the class name '{class_declaration}' were found."
+            )
+            raise Exception("No cells found with the specified class name")
+
         extracted_notebook = nbformat.v4.new_notebook()
-        extracted_notebook.cells = [notebook.cells[i] for i in cell_indices]
-    except IndexError as e:
-        logger.error(f"Error: Cell index out of range. {e}")
+        extracted_notebook.cells = extracted_cells
+    except Exception as e:
+        logger.error(f"Error while extracting cells: {e}")
         raise
 
     # Convert the notebook to a Python script
     return convert_notebook_to_script(extracted_notebook, output_path)
 
 
 def convert_notebook_to_script(notebook, output_path):
```

## finter/framework_model/submission/helper_simulation.py

```diff
@@ -1,18 +1,155 @@
 import json
 from enum import Enum
 
 import pandas as pd
 
 from finter.framework_model.simulation import adj_stat_container_helper
+from finter.framework_model.submission.config import (
+    DefaultBenchmark,
+    get_model_info,
+    validate_and_get_benchmark_name,
+    validate_and_get_model_type_name,
+)
+from finter.settings import log_section, log_with_traceback, log_with_user_event, logger
 from finter.utils.timer import timer
 
 
+class Simulation:
+    """
+    A class representing a financial model simulation.
+
+    Attributes:
+        model_universe (str): The model universe for the simulation.
+        model_type (str): The model type for the simulation.
+        position (pd.DataFrame): The position for the simulation.
+        benchmark (str, optional): The benchmark for the simulation. Defaults to None.
+
+    Methods:
+        run(start, end, **kwargs):
+            Runs the simulation based on the model's configuration.
+    """
+
+    def __init__(self, model_universe, model_type, position, benchmark=None):
+        """
+        Initializes a Simulation object with the required parameters for running a financial model simulation.
+
+        Args:
+            model_universe (str): The model universe for the simulation.
+            model_type (str): The model type for the simulation.
+            position (pd.DataFrame): The position for the simulation.
+            benchmark (str, optional): The benchmark for the simulation. Defaults to None.
+
+        Example:
+            >>> sim = Simulation(model_universe=universe, model_type=model_type, position=position, benchmark=None)
+            >>> model_stat = sim.run(start=20200101, end=20210101)
+        """
+
+        self.position = position
+
+        self.model_info = get_model_info(model_universe, model_type)
+        self.model_type = validate_and_get_model_type_name(model_type)
+        self.benchmark = validate_and_get_benchmark_name(model_universe, benchmark)
+
+        self.model_stat = None
+
+    def run(self, start, end, **kwargs):
+        """
+        Executes the simulation for the given period using the specified model configuration.
+
+        Args:
+            start (int): The start date for the simulation in YYYYMMDD format.
+            end (int): The end date for the simulation in YYYYMMDD format.
+            **kwargs: Additional keyword arguments to customize the simulation settings.
+
+        Keyword Args:
+            volcap_pct (float): Volume cap as a percentage, limiting the amount of shares to be traded.
+            decay (float): Decay factor to apply to the model's signals over time.
+            cost_list (list[float]): A list of transaction costs associated with trading, expressed in percentage terms.
+            slippage (float): Estimated slippage cost per trade, reflecting the impact of market impact.
+            return_calc_method (str): Method for calculating returns ('arithmetic' or 'geometric').
+            turnover_calc_method (str): Method to calculate turnover during the simulation.
+            booksize (float): Total value of the book to be managed in the simulation.
+            close (bool): Flag to indicate whether positions should be closed at the end of the simulation.
+            adj_dividend (bool): Flag to adjust returns for dividends.
+
+        Returns:
+            ModelStat: An object containing the detailed results of the simulation, including performance metrics and statistical analysis.
+
+        Raises:
+            Exception: Captures and logs any exceptions during the simulation, providing error details for troubleshooting.
+        """
+        log_section("Simulation")
+
+        # Determine the return calculation method based on the model type
+        if self.model_type.lower() == "alpha":
+            return_calc_method = "arithmetic"
+        else:
+            return_calc_method = "geometric"
+
+        try:
+            model_stat = run_simulation(
+                self.model_info,
+                start,
+                end,
+                position=self.position,
+                return_calc_method=return_calc_method,
+                benchmark=self.benchmark,
+                **kwargs,
+            )
+        except Exception as e:
+            log_with_user_event(
+                "model_simulation_error",
+                source="Simulation",
+                method="run",
+                category="error",
+                log_type="error",
+                log_message=str(e),
+            )
+            log_with_traceback(f"Error occurred during simulation run: {e}")
+            raise
+
+        log_with_user_event(
+            "model_simulation_success",
+            source="Simulation",
+            method="run",
+            category="info",
+            log_type="info",
+            log_message="Simulation run successfully based on the extracted positions.",
+        )
+        return model_stat
+
+
 @timer
 def run_simulation(model_info, start, end, **kwargs):
+    """
+    Runs a simulation based on the given model information and time range, applying additional specified settings.
+
+    This function initializes the simulation with default parameters, which can be overridden by the kwargs argument. It processes the model statistics using the 'adj_stat_container_helper' function, then creates and returns a ModelStat object populated with the simulation results and any additional settings.
+
+    Parameters:
+    - model_info: An object containing model configuration information.
+    - start (datetime): The start date of the simulation.
+    - end (datetime): The end date of the simulation.
+    - **kwargs: Optional keyword arguments to specify additional simulation settings. Default values are:
+        - volcap_pct: 1 (Volume cap percentage),
+        - decay: 1 (Decay factor for the model),
+        - cost_list: ["hi_low", "fee_tax"] (List of transaction costs to consider),
+        - slippage: 10 (Slippage in the model's transactions),
+        - return_calc_method: "arithmetic" (Method for calculating returns),
+        - turnover_calc_method: "diff" (Method for calculating turnover),
+        - booksize: 1e8 (Size of the book in the simulation),
+        - close: True (Whether to close the positions at the end of the simulation),
+        - adj_dividend: False (Whether to adjust for dividends).
+
+    Returns:
+    - A ModelStat object containing the results of the simulation along with the settings used for the simulation.
+
+    The 'kwargs' argument allows for flexible configuration of the simulation, accommodating various scenarios and model behaviors.
+    """
     defaults = {
         "volcap_pct": 1,
         "decay": 1,
         "cost_list": ["hi_low", "fee_tax"],
         "slippage": 10,
         "return_calc_method": "arithmetic",
         "turnover_calc_method": "diff",
@@ -20,59 +157,86 @@
         "close": True,
         "adj_dividend": False,
     }
 
     for key, value in defaults.items():
         kwargs.setdefault(key, value)
 
+    benchmark = kwargs.pop("benchmark", None)
+
     model_stat = adj_stat_container_helper(
         model_info=model_info, start=start, end=end, **kwargs
     )
 
-    return ModelStat(model_stat)
+    kwargs.pop("position", None)
+
+    return ModelStat(model_stat, benchmark, **kwargs)
 
 
 class ModelStat:
+    """
+    A class that manages the extraction and manipulation of statistical data for financial models.
+
+    This class provides methods to access various statistics at different frequencies and integrates benchmark comparisons if provided.
+
+    Attributes:
+        model_stat (dict): A dictionary containing statistical data for the model.
+        benchmark (str): An optional benchmark identifier for comparison.
+        kwargs (dict): Additional keyword arguments that may affect computations, such as 'return_calc_method'.
+
+    Methods:
+        extract_statistics(frequency): Returns a DataFrame of statistics based on the specified frequency.
+        whole_period, yearly, half_yearly, quarterly, monthly, weekly, daily: Properties that return statistics for their respective frequencies.
+        cummulative_return: Calculates and returns the cumulative returns adjusted for the benchmark, if applicable.
+        raw_return: Calculates and returns the raw returns based on the cumulative returns.
+
+    Raises:
+        ValueError: If an invalid frequency is specified for statistics extraction.
+    """
+
     class Frequency(Enum):
         WholePeriod = "WholePeriod"
         Yearly = "Yearly"
         HalfYearly = "HalfYearly"
         Quarterly = "Quarterly"
         Monthly = "Monthly"
         Weekly = "Weekly"
         Daily = "Daily"
 
-    def __init__(self, model_stat):
-        """Initialize the ModelStat object with statistical data.
+    def __init__(self, model_stat, benchmark, **kwargs):
+        """
+        Initializes the ModelStat object with statistical data, an optional benchmark, and other keyword arguments.
 
         Parameters:
-        - statistics: A dictionary containing statistical data.
+            model_stat (dict): Dictionary containing the statistical data for the model.
+            benchmark (str): The benchmark identifier for comparison purposes. Set to None if no benchmark is used.
+            **kwargs: Additional keyword arguments that can influence the processing of returns and other calculations.
+
+        Note:
+            If benchmark is not False and is provided, the benchmark data will be fetched and stored for comparison purposes.
         """
         self.model_stat = model_stat
+        self.benchmark = benchmark
+        self.kwargs = kwargs
 
-    def extract_statistics(self, frequency):
-        """Extracts statistics for a given frequency.
+        if benchmark is not False:
+            self.bm = DefaultBenchmark(self.benchmark).get_benchmark_df()
 
-        This method transforms statistical data into a DataFrame based on the specified frequency.
+    def extract_statistics(self, frequency):
+        """
+        Extracts statistical data for a specified frequency and returns it as a pandas DataFrame.
 
         Parameters:
-        - frequency (str): The frequency for the statistical data. Must be one of the following:
-            - 'WholePeriod'
-            - 'Yearly'
-            - 'HalfYearly'
-            - 'Quarterly'
-            - 'Monthly'
-            - 'Weekly'
-            - 'Daily'
+            frequency (str): The frequency of the statistical data to be extracted. Valid options are 'WholePeriod', 'Yearly', 'HalfYearly', 'Quarterly', 'Monthly', 'Weekly', 'Daily'.
 
         Returns:
-        - A pandas DataFrame containing the statistical data for the specified frequency.
+            pandas.DataFrame: A DataFrame containing the statistical data for the specified frequency.
 
         Raises:
-        - ValueError: If the frequency is not one of the valid options.
+            ValueError: If the specified frequency is not one of the valid options listed in the Frequency enum.
         """
         try:
             frequency = self.Frequency(frequency).value
         except ValueError:
             valid_options = ", ".join(
                 [f"'{option.value}'" for option in self.Frequency]
             )
@@ -83,21 +247,68 @@
         parsed_json = json.loads(self.model_stat["statistics"][frequency])
 
         df = pd.DataFrame(
             parsed_json["data"],
             columns=parsed_json["columns"],
             index=pd.to_datetime(parsed_json["index"]),
         )
-        df.index = pd.to_datetime(df.index).to_series().apply(lambda x: x.date())
+        df.index = pd.to_datetime(df.index).date
 
         return df
 
+    @property
+    def whole_period(self):
+        return self.extract_statistics("WholePeriod")
+
+    @property
+    def yearly(self):
+        return self.extract_statistics("Yearly")
+
+    @property
+    def half_yearly(self):
+        return self.extract_statistics("HalfYearly")
+
+    @property
+    def quarterly(self):
+        return self.extract_statistics("Quarterly")
+
+    @property
+    def monthly(self):
+        return self.extract_statistics("Monthly")
+
+    @property
+    def weekly(self):
+        return self.extract_statistics("Weekly")
+
+    @property
+    def daily(self):
+        return self.extract_statistics("Daily")
+
+    @property
     def cummulative_return(self):
         cum_ret = pd.read_json(self.model_stat["cum_ret"], orient="records").set_index(
             "index"
         )["data"]
-        cum_ret.index = (
-            pd.to_datetime(cum_ret.index).to_series().apply(lambda x: x.date())
-        )
-        cum_ret.plot()
+        cum_ret.index = pd.to_datetime(cum_ret.index).date
 
+        if self.benchmark is False:
+            cum_ret.columns = ["model"]
+        else:
+            logger.info(f"benchmark: {self.benchmark if self.benchmark else 'default'}")
+
+            bm = self.bm.reindex(cum_ret.index)
+            bm = bm.pct_change(fill_method=None).fillna(0)
+            if self.kwargs["return_calc_method"] == "arithmetic":
+                bm = bm.cumsum()
+            else:
+                bm = (1 + bm).cumprod() - 1
+            cum_ret = pd.concat([cum_ret, bm], axis=1)
+            cum_ret.columns = ["model", self.benchmark]
         return cum_ret
+
+    @property
+    def raw_return(self):
+        if self.kwargs["return_calc_method"] == "arithmetic":
+            raw_ret = self.cummulative_return.diff()
+        else:
+            raw_ret = (1 + self.cummulative_return).pct_change(fill_method=None)
+        return raw_ret
```

## finter/framework_model/submission/notebook.py

```diff
@@ -1,113 +1,124 @@
 from finter.framework_model.submission.config import (
-    ModelTypeConfig,
-    ModelUniverseConfig,
+    get_model_info,
+    validate_and_get_benchmark_name,
+    validate_and_get_model_type_name,
 )
 from finter.framework_model.submission.helper_github import commit_folder_to_github
 from finter.framework_model.submission.helper_notebook import (
     extract_and_convert_notebook,
 )
 from finter.framework_model.submission.helper_position import load_and_get_position
-from finter.framework_model.submission.helper_simulation import run_simulation
+from finter.framework_model.submission.helper_simulation import Simulation
 from finter.framework_model.submission.helper_submission import submit_model
 from finter.framework_model.validation import ValidationHelper
-from finter.settings import log_section, logger
+from finter.settings import (
+    log_section,
+    log_warning,
+    log_with_traceback,
+    log_with_user_event,
+    logger,
+)
 
 
 class NotebookSubmissionHelper:
     """
     A helper class to facilitate the submission process of financial models
     developed in Jupyter Notebooks. It supports extracting relevant cells from a
     notebook, running simulations, performing validations, and submitting the model
     for further use or evaluation.
 
     Attributes:
-        cell_indices (list): Indices of the cells to extract from the notebook.
         notebook_name (str): The name of the notebook file (including path if necessary).
-        model_name (str): The name of the model to be submitted.
+        model_name (str): The path where the model will be saved. The last part of the path is considered the name of the model. For example, 'path/to/model_name' would save the model in the 'path/to/' directory with 'model_name' as the model name.
         model_universe (str): The universe for the model (e.g. "kr_stock").
         model_type (str): The type of the model (e.g. "alpha" or "portfolio").
+        benchmark (str): The benchmark to use for the model. Default is None. If not specified, the default benchmark for the model universe will be used. If False, no benchmark will be used.
     """
 
     def __init__(
         self,
-        cell_indices,
         notebook_name,
         model_name,
         model_universe,
         model_type="alpha",
+        benchmark=None,
     ):
         """
         Initializes the NotebookSubmissionHelper with necessary information.
 
-        Parameters:
-            cell_indices (list): Indices of the cells to extract from the notebook.
+        Args:
             notebook_name (str): The name of the notebook file (including path if necessary).
-            model_name (str): The name of the model to be submitted.
+            model_name (str): The path where the model will be saved. The last part of the path is considered the name of the model. This allows for specifying the directory to save the model along with the model's name. For example, 'path/to/model_name' would save the model in the 'path/to/' directory with 'model_name' as the model name.
             model_universe (str): The universe for the model (e.g. "kr_stock").
             model_type (str): The type of the model (e.g. "alpha" or "portfolio").
+            benchmark (str): The benchmark to use for the model. Default is None. If not specified, the default benchmark for the model universe will be used. If False, no benchmark will be used.
         """
-        self.cell_indices = cell_indices
+        log_warning(
+            "!!! IMPORTANT: Please ensure your current notebook is SAVED before proceeding with the submission process. !!!"
+        )
+
         self.notebook_name = notebook_name
         self.model_name = model_name
-        try:
-            self.model_type = ModelTypeConfig[model_type.upper()].name
-        except KeyError:
-            logger.error(
-                f"Invalid model type: {model_type}. Available options: {ModelTypeConfig.available_options()}"
-            )
-            raise
-
-        try:
-            self.model_info = ModelUniverseConfig[model_universe.upper()].get_config(
-                model_type=ModelTypeConfig[model_type.upper()]
-            )
-        except KeyError:
-            logger.error(
-                f"Invalid model universe: {model_universe}. Available options: {ModelUniverseConfig.available_options()}"
-            )
-            raise
+        self.notebook_name = notebook_name
+        self.model_name = model_name
+        self.model_universe = model_universe
+
+        self.model_info = get_model_info(model_universe, model_type)
+        self.model_type = validate_and_get_model_type_name(model_type)
+        self.benchmark = validate_and_get_benchmark_name(model_universe, benchmark)
 
     def process(
         self,
-        start,
-        end,
+        start: int,
+        end: int,
         position=False,
         simulation=False,
         validation=False,
         submit=False,
         git=False,
     ):
         """
-        Processes the notebook by extracting specified cells, and optionally running position extraction,
-        simulation, validation, and submission steps. Validation is automatically performed if submission is
-        requested. Position extraction is mandatory for simulation.
-
-        Parameters:
-            start (str): The start date for the simulation and validation processes.
-            end (str): The end date for the simulation and validation processes.
+        Processes the notebook by extracting specified cells, and optionally running position extraction, simulation, validation, and submission steps. Validation is automatically performed if submission is requested. Position extraction is mandatory for simulation.
+
+        Args:
+            start (int): The start date for the simulation and validation processes.
+            end (int): The end date for the simulation and validation processes.
             position (bool): Flag to determine whether to extract positions from the model. Default is False.
             simulation (bool): Flag to determine whether to run a simulation based on the extracted positions. Default is False.
             validation (bool): Flag to determine whether to validate the model. Default is False.
             submit (bool): Flag to determine whether to submit the model. Default is False.
             git (bool): Flag to determine whether to commit the model to GitHub. Default is False.
         """
         # Extract and convert the notebook
         log_section("Notebook Extraction")
         output_file_path = extract_and_convert_notebook(
-            self.cell_indices,
             self.notebook_name,
             self.model_name,
             model_type=self.model_type,
         )
 
         if not output_file_path:
-            logger.error("Error extracting notebook.")
+            log_with_user_event(
+                "notebook_extraction_error",
+                "finter",
+                "notebook_submission",
+                "notebook",
+                log_type="error",
+                log_message="Error extracting notebook.",
+            )
             return
-        logger.info(f"Notebook extracted to {output_file_path}")
+        log_with_user_event(
+            "notebook_extraction_success",
+            "finter",
+            "notebook_submission",
+            "notebook",
+            log_type="info",
+            log_message=f"Notebook extracted to {output_file_path}",
+        )
 
         # Ensure position extraction if simulation is requested
         if simulation and not position:
             position = True
             logger.warning(
                 "Position extraction is required for simulation. Setting position=True."
             )
@@ -115,41 +126,109 @@
         # Perform position extraction if required
         if position:
             log_section("Position Extraction")
             self.position = load_and_get_position(
                 start, end, output_file_path, model_type=self.model_type
             )
             if self.position is None:
-                logger.error("Error running notebook for position extraction.")
-                return
-            logger.info("Position extraction from notebook ran successfully.")
+                log_with_user_event(
+                    "position_extraction_error",
+                    "finter",
+                    "notebook_submission",
+                    "position",
+                    log_type="error",
+                    log_message="Error extracting positions from notebook.",
+                )
+                raise ValueError("Error extracting positions from notebook.")
+            log_with_user_event(
+                "position_extraction_success",
+                "finter",
+                "notebook_submission",
+                "position",
+                log_type="info",
+                log_message="Position extraction from notebook ran successfully.",
+            )
 
         # Run simulation with the extracted positions if requested
         if simulation:
-            log_section("Simulation")
-            self.model_stat = run_simulation(
-                self.model_info, start, end, position=self.position
-            )
-            logger.info("Simulation run successfully based on the extracted positions.")
+            self.model_stat = Simulation(
+                model_universe=self.model_universe,
+                model_type=self.model_type,
+                position=self.position,
+                benchmark=self.benchmark,
+            ).run(start, end)
 
         # Validate the model if requested
         if validation:
             log_section("Validation")
-            validator = ValidationHelper(
-                model_path=self.model_name, model_info=self.model_info
+
+            try:
+                validator = ValidationHelper(
+                    model_path=self.model_name, model_info=self.model_info
+                )
+                validator.validate()
+            except Exception as e:
+                log_with_user_event(
+                    "model_validation_error",
+                    "finter",
+                    "notebook_submission",
+                    "validation",
+                )
+                log_with_traceback(f"Error validating the model: {e}")
+                raise
+
+            log_with_user_event(
+                "model_validation_success",
+                "finter",
+                "notebook_submission",
+                "validation",
+                log_type="info",
+                log_message="Model validation completed successfully.",
             )
-            validator.validate()
-            logger.info("Model validated successfully.")
 
         # Submit the model if requested
         if submit:
             log_section("Model Submission")
             self.submit_result = submit_model(self.model_info, self.model_name)
-            logger.info("Model submitted successfully.")
+            if self.submit_result is None:
+                log_with_user_event(
+                    "model_submission_error",
+                    "finter",
+                    "notebook_submission",
+                    "submission",
+                    log_type="error",
+                    log_message="Error submitting the model.",
+                )
+                raise
+            log_with_user_event(
+                "model_submission_success",
+                "finter",
+                "notebook_submission",
+                "submission",
+                log_type="info",
+                log_message="Model submitted successfully.",
+            )
 
         # Commit the model to GitHub if requested
         if git:
             log_section("GitHub Commit")
-            commit_folder_to_github(
-                folder_path=self.model_name
+            try:
+                commit_folder_to_github(folder_path=self.model_name)
+            except Exception as e:
+                log_with_user_event(
+                    "model_commit_error",
+                    "finter",
+                    "notebook_submission",
+                    "github",
+                    log_type="error",
+                    log_message="Error committing the model to GitHub.",
+                )
+                log_with_traceback(f"Error committing the model to GitHub: {e}")
+                raise
+            log_with_user_event(
+                "model_commit_success",
+                "finter",
+                "notebook_submission",
+                "github",
+                log_type="info",
+                log_message="Model committed to GitHub successfully.",
             )
-            logger.info("Model committed to GitHub successfully.")
```

## finter/models/__init__.py

```diff
@@ -14,14 +14,15 @@
 from __future__ import absolute_import
 
 # import models into model package
 from finter.models.all_of_content_data_response_valid_data_graph import AllOfContentDataResponseValidDataGraph
 from finter.models.all_of_metafund_performance_response_threeyears import AllOfMetafundPerformanceResponseThreeyears
 from finter.models.alpha_identities_response import AlphaIdentitiesResponse
 from finter.models.alpha_model_response import AlphaModelResponse
+from finter.models.aws_credentials_response import AwsCredentialsResponse
 from finter.models.base_alpha_content_model_response import BaseAlphaContentModelResponse
 from finter.models.content_category_response import ContentCategoryResponse
 from finter.models.content_data_request import ContentDataRequest
 from finter.models.content_data_response import ContentDataResponse
 from finter.models.content_identites_response import ContentIdentitesResponse
 from finter.models.content_model_response import ContentModelResponse
 from finter.models.flexible_fund_identities_response import FlexibleFundIdentitiesResponse
```

## finter/models/simulation_request.py

```diff
@@ -42,15 +42,16 @@
         'slippage': 'float',
         'reinvest': 'bool',
         'fill_nan': 'bool',
         'close': 'bool',
         'legends': 'dict(str, object)',
         'adj_dividend': 'bool',
         'adj_funding_fee': 'bool',
-        'currency': 'str'
+        'currency': 'str',
+        'statistics_filter': 'list[str]'
     }
 
     attribute_map = {
         'position': 'position',
         'position_column_types': 'position_column_types',
         'model_info': 'model_info',
         'start': 'start',
@@ -64,18 +65,19 @@
         'slippage': 'slippage',
         'reinvest': 'reinvest',
         'fill_nan': 'fill_nan',
         'close': 'close',
         'legends': 'legends',
         'adj_dividend': 'adj_dividend',
         'adj_funding_fee': 'adj_funding_fee',
-        'currency': 'currency'
+        'currency': 'currency',
+        'statistics_filter': 'statistics_filter'
     }
 
-    def __init__(self, position=None, position_column_types=None, model_info=None, start=None, end=None, volcap_pct=0.0, cost_list=None, decay=1, return_calc_method='arithmetic', turnover_calc_method='arithmetic', booksize=100000000, slippage=0.0, reinvest=False, fill_nan=True, close=False, legends=None, adj_dividend=False, adj_funding_fee=False, currency=None):  # noqa: E501
+    def __init__(self, position=None, position_column_types=None, model_info=None, start=None, end=None, volcap_pct=0.0, cost_list=None, decay=1, return_calc_method='arithmetic', turnover_calc_method='arithmetic', booksize=100000000, slippage=0.0, reinvest=False, fill_nan=True, close=False, legends=None, adj_dividend=False, adj_funding_fee=False, currency=None, statistics_filter=None):  # noqa: E501
         """SimulationRequest - a model defined in Swagger"""  # noqa: E501
         self._position = None
         self._position_column_types = None
         self._model_info = None
         self._start = None
         self._end = None
         self._volcap_pct = None
@@ -88,14 +90,15 @@
         self._reinvest = None
         self._fill_nan = None
         self._close = None
         self._legends = None
         self._adj_dividend = None
         self._adj_funding_fee = None
         self._currency = None
+        self._statistics_filter = None
         self.discriminator = None
         self.position = position
         self.position_column_types = position_column_types
         self.model_info = model_info
         self.start = start
         self.end = end
         if volcap_pct is not None:
@@ -122,14 +125,16 @@
             self.legends = legends
         if adj_dividend is not None:
             self.adj_dividend = adj_dividend
         if adj_funding_fee is not None:
             self.adj_funding_fee = adj_funding_fee
         if currency is not None:
             self.currency = currency
+        if statistics_filter is not None:
+            self.statistics_filter = statistics_filter
 
     @property
     def position(self):
         """Gets the position of this SimulationRequest.  # noqa: E501
 
 
         :return: The position of this SimulationRequest.  # noqa: E501
@@ -532,14 +537,35 @@
 
         :param currency: The currency of this SimulationRequest.  # noqa: E501
         :type: str
         """
 
         self._currency = currency
 
+    @property
+    def statistics_filter(self):
+        """Gets the statistics_filter of this SimulationRequest.  # noqa: E501
+
+
+        :return: The statistics_filter of this SimulationRequest.  # noqa: E501
+        :rtype: list[str]
+        """
+        return self._statistics_filter
+
+    @statistics_filter.setter
+    def statistics_filter(self, statistics_filter):
+        """Sets the statistics_filter of this SimulationRequest.
+
+
+        :param statistics_filter: The statistics_filter of this SimulationRequest.  # noqa: E501
+        :type: list[str]
+        """
+
+        self._statistics_filter = statistics_filter
+
     def to_dict(self):
         """Returns the model properties as a dict"""
         result = {}
 
         for attr, _ in six.iteritems(self.swagger_types):
             value = getattr(self, attr)
             if isinstance(value, list):
```

## finter/utils/__init__.py

```diff
@@ -1,2 +1,2 @@
 from finter.utils.convert import to_dataframe
-from finter.utils.func_utils import lazy_call
+from finter.utils.func_utils import lazy_call, with_spinner
```

## finter/utils/func_utils.py

```diff
@@ -1,11 +1,58 @@
+import sys
+
 from functools import wraps
+from halo import Halo
+
+
+def is_notebook():
+    """True => Halo not working"""
+    try:
+        shell = get_ipython().__class__.__name__
+        if shell == 'ZMQInteractiveShell':
+            return True
+        elif shell == 'TerminalInteractiveShell':
+            return False  # Terminal running IPython
+        else:
+            return False  # Other type (?)
+    except NameError:
+        return False  # Probably standard Python interpreter
 
 
 def lazy_call(f):
     @wraps(f)
     def wrapper(*args, **kwargs):
         def inner_call(**late_kwargs):
             complete_kwargs = {**kwargs, **late_kwargs}
             return f(*args, **complete_kwargs)
+
         return inner_call
+
     return wrapper
+
+
+def with_spinner(
+        text='Processing...',
+        msg_success='Completed!',
+        msg_failed='An error occurred!',
+        spinner_type='dots'):
+    def decorator(func):
+        @wraps(func)
+        def wrapper(*args, **kwargs):
+            if is_notebook() is False:
+                spinner = Halo(text=text, spinner=spinner_type)
+                spinner.start()
+                try:
+                    result = func(*args, **kwargs)
+                    spinner.succeed(msg_success)
+                    spinner.stop()
+                    return result
+                except Exception as e:
+                    spinner.fail(msg_failed)
+                    raise e
+            else:
+                result = func(*args, **kwargs)
+                return result
+
+        return wrapper
+
+    return decorator
```

## Comparing `finter-0.1.9.dist-info/RECORD` & `finter-0.2.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,68 +1,83 @@
-finter/__init__.py,sha256=z6oIRMwHeLVFym-c-S4EtH1r-85hL4Y8ldA55rVhyMo,3693
+finter/__init__.py,sha256=tNZIfsyr4jsnkRqj7imgJC4tmydDVPWoKFuxhKkJ4lI,4121
 finter/api_client.py,sha256=Nu50M68HUsf5IP3cwaVMu_H9zjaG1N2RkmXXRTrafZk,25315
 finter/configuration.py,sha256=INHSAlxyi_P60Ry_4L3mFgKMYLoZutquMhB-Qbc6cw4,8871
 finter/rest.py,sha256=_fSjcTeXiUHxrw6waqtY1tzuN4gBS2lYWvzfB9QnuPU,13299
-finter/settings.py,sha256=c1jr9wi3luMgY3wX1xYo2cTRbMo8Tr1udyqwGdJagLI,1590
+finter/settings.py,sha256=jviFL7CeXBDkwaaq_eqW3pE-7Xqrzk3GZIln231ecOM,2946
 finter/ai/__init__.py,sha256=qPXivjCMhTsCsUjUmEvM54A-DM-POUjXBX2tsmquv24,39
 finter/ai/gpt/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finter/ai/gpt/chat.py,sha256=1dPcvXEqZZTUdpZtjWpADfIVsPT0vowYrOMBKL5l2Eg,335
+finter/ai/gpt/cm_docs.py,sha256=yRsfMNx7_UijxNKB97nsI-5ubRmMu--JNuLfYRDeOhs,500
 finter/ai/gpt/config.py,sha256=9M5EYY6fw4djaVN3NPO2w-rRr8n7l9cFT94Zxo_qZ0U,39
-finter/ai/gpt/cookbook.py,sha256=RbWSTUB01wovV1CyLwcwmW2I9ZVfkkZE9iSRItSkD3Y,618
-finter/ai/gpt/release_note.py,sha256=g3kM2-LWtsNlOFf9V3_1gvgIbzitEXfklmrnysmtbrE,661
-finter/api/__init__.py,sha256=NnwAXb-HbiuZN6A8FNp2lBgxbqv-peFdCTmF1pfmy_Y,619
+finter/ai/gpt/cookbook.py,sha256=598XwZQ6enImMWlqBK0zomWSoWiozfPP3lk-oFMSuxs,611
+finter/ai/gpt/release_note.py,sha256=WCHIRe9DXEkqv6dvObDfQlLPGV-M-7xfbhXbEZaMGus,1138
+finter/ai/quanda_bot/__init__.py,sha256=DL7Xx7IS0XSx2KHh4QHUsbsk3u_d2-_1tAzmpnB3JuY,60
+finter/ai/quanda_bot/generate.py,sha256=AGElLZ4KGgd2OUhuM8sLpPJZfVD0OgG1ap6MUKoUncM,2271
+finter/api/__init__.py,sha256=MOZ7Z1TKCPgln_JmIxJCtW6UxS-ubSZljoSmtU386ic,680
 finter/api/alpha_api.py,sha256=ZxbRQ1OSaT3KCG8BALrSGMkDz4Uw1RBnierj-fo7hMA,19412
+finter/api/aws_credentials_api.py,sha256=bHRvAaMvmgViLRlS4Fakk7zfgUUt9GfeB2irNywMicY,4177
 finter/api/calendar_api.py,sha256=H95IHRNvRzhh_U9i2iwupYIT_w0h0Au3q6CLheSRvOg,11068
 finter/api/content_api.py,sha256=ny7WbVp-J7slUTYwXC8IeNRWstu5Kjjuy59_ig75jos,14436
 finter/api/default_api.py,sha256=9Rwm1TsVVX2jpLXwVG77M7V5xaCtJY96AO9-Vym-n6s,19582
 finter/api/flexible_fund_api.py,sha256=D3_R11wtqcB8Y0l660HMoyLo4aSp6WO7V23Xi7KLI8U,11384
 finter/api/fund_api.py,sha256=0HviRdx9xvio-EYzxGYh8-Vk6sg5Q2xzBJKx8_0QiaY,11088
 finter/api/metafund_api.py,sha256=qQgv95RTde6h6r4szSz3M5-bZnG-6IhPDqT6nZ6uiS0,12002
 finter/api/performance_api.py,sha256=RJIb-4w9UgYMJhbBZK4T-HfMU2So7l5MuootXPGDkik,7040
 finter/api/portfolio_api.py,sha256=oqKJu0IzQyjUJLs5VGEgYq2GRZYo_yu9GsflGcYmpYY,18410
 finter/api/quanda_bot_api.py,sha256=_PEvyv8ZdhPdhHTYdFhHaPAuJD7HSA074nIQXJAX-2k,4523
+finter/api/quanda_data_api.py,sha256=yKJoQsaKa6HzDdf59R4GzjQTH6OliSUD3L1dehFYkx8,7663
 finter/api/simulation_api.py,sha256=Ylb2EoP8_gJ7EEWjSd9LWv0pH4V_OfSPfSg4QfuaeTU,4810
-finter/api/sm_api.py,sha256=upgF9n0ZKDGBFisfxYFRQyIdOtuCqKUE8L9GF7dN55I,4281
-finter/api/submission_api.py,sha256=GitbZ43Z0w3f9a3B3q7njU0XpmmgSrx7n1sFI4nDUFg,6508
+finter/api/sm_api.py,sha256=ssm0sDiE2ngLJJS3KWfy8Eyy9V2vXeVS7_BasM686PM,4482
+finter/api/submission_api.py,sha256=JSFAZQd5BZqeNBTngrvLcehpJAOrottQ3bPcUWVAJDQ,6716
 finter/api/universe_api.py,sha256=rwmqURZicPSEnUuFS_yKgB--NmXt81PMpwlHLvANvEc,6777
-finter/data/__init__.py,sha256=FrKzIxKlTVrLDEb-phAX5u-pu0BUCLXshHtuoLfj8_4,38
-finter/data/load.py,sha256=GE92FDPbZovQZ20VbNuuMljpeomxEjPTk-CiWvWD1tM,3766
-finter/framework_model/__init__.py,sha256=Bo8hx7HrIjbxMC25W8THcJkZ22cveipKkx5Bkr1qByo,632
+finter/api/user_api.py,sha256=O4RkRTL7gBNiytcNBc-ja0BaTTOLKThB3PrAZJiQta4,6084
+finter/calendar/__init__.py,sha256=-7ZERnLKL0o3ANaPuX6-ESxg2D4LUvPAeWWby7SwkjI,105
+finter/data/__init__.py,sha256=N-5ITewky-U71gFPGQNRl1CloCMMJ8TsvQZmcWnGowY,98
+finter/data/load.py,sha256=6Pvm6YFMvLTbfNGJSyPf9ZbJwWc8iKCk8YqHpEx94Mk,5936
+finter/data/content_model/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+finter/data/content_model/catalog_sheet.py,sha256=7i7XrelafITODsi17h9FYfyvKLoobbDKig8tsxmTEEg,275
+finter/data/content_model/loader.py,sha256=JgThwpt30kMdV1YifCLTCpHCA7jv7Svmhv5IlKNjMaU,5134
+finter/framework_model/__init__.py,sha256=M03jcsWPeZ1wVKorrhk55V7e97pfazd9W0Pfd4c0pcY,570
 finter/framework_model/alpha.py,sha256=NyUqgCAoPERpRBmNi3N7YjPyegRsqGV7YQSQeHrCxlM,529
 finter/framework_model/alpha_loader.py,sha256=ZkkgKLZapDV3btpKnQGaDH9FljkNsQHLZRAwCq_9JyQ,1466
+finter/framework_model/aws_credentials.py,sha256=ASWYwU8kNyG59CXNGPBO9WxOqN2FA-Hbqp90vbtXRXU,1198
 finter/framework_model/calendar.py,sha256=nrVMUfSw3zWWIIwuwM3NWzw8Dp4Eqdr5CjZmi55rg0Y,4994
 finter/framework_model/cm_loader.py,sha256=-Ir16W1HPhTK9DgNPmA-3PQniirCa8Fibbid1y0_LBk,1184
 finter/framework_model/portfolio.py,sha256=dDhibvA3Y08HVP8TBRRh5MyEQbrIseqdGbi60FV6KJo,902
-finter/framework_model/simulation.py,sha256=m0ndziRqL0qUuMPrwWPEuz0KT9boaGY1_fsZ-8EvrpA,707
+finter/framework_model/simulation.py,sha256=TZgRUVTwcCMewx_cn4ZAw0ULg9B7UGZErNEE94Zk6BE,796
 finter/framework_model/universe.py,sha256=4DDfIhGUzTEbSbLfGiw6n_iJGyxFbcid3jki_qNkX_A,788
-finter/framework_model/validation.py,sha256=mY05A4E86DuYb9Rc0qFWIh4WLT_GQL9viukpeM5LVg8,7012
+finter/framework_model/validation.py,sha256=71wk9M4rkedBHrMCJ8wCMdpp2MJSir4vGbPpfGAgJI4,7224
 finter/framework_model/submission/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finter/framework_model/submission/config.py,sha256=6aYI87iVU_54YYF4Cc4-lqsIbfD8fesz14QWPi2Sejs,1097
+finter/framework_model/submission/config.py,sha256=qMEMIujPfBD_wEA70vivHsHE4mJACmtsCBHScn44d14,2946
 finter/framework_model/submission/helper_github.py,sha256=CzXXN-gfGY9whhRlKoqjRO4iU3uvExGfWB-n5iiH5tQ,3500
 finter/framework_model/submission/helper_github_config.py,sha256=ndXgOIlG9wjXhkVf-AoKqhPkPp0AJ7Tc1el_6sqzQwE,218
-finter/framework_model/submission/helper_notebook.py,sha256=XBQgUUdGxkMW0mzStHa7iOjLF4WSCfZ5ivY3S6G5Vi8,2815
+finter/framework_model/submission/helper_notebook.py,sha256=jSlilYr5txFZhiSBEX1NfXQl9vkjoM-yvTbvuOSTvi8,3063
 finter/framework_model/submission/helper_position.py,sha256=7rKaF_RJoa5XK74sCAN5GDyOmw7MJelqoVPdq6vzbEg,2036
-finter/framework_model/submission/helper_simulation.py,sha256=M7piqQFDkcX4mUQwsdT3isA0uT_SARXbBg14_miz1Sk,2979
+finter/framework_model/submission/helper_simulation.py,sha256=xn8hlqJluvKU0Ri1LsM8zp2Yx4NOvDvprmUiI_qIR_8,12428
 finter/framework_model/submission/helper_submission.py,sha256=ncV6N6V-wzjrjpR9Pk_zce5hf3e2G1KdQy_oSzwZSro,664
-finter/framework_model/submission/notebook.py,sha256=Y8W3tBc5-5nbtA9swppO-okkrkiao1PxiJ7YC99NuIE,6423
-finter/models/__init__.py,sha256=aRrrsF4rDrlrFgyqrVMU1UpH8Cx7uhzFCLqiNMDW4AI,3022
+finter/framework_model/submission/notebook.py,sha256=8l7gfK9W0IiL9CMwPsm_HtgiKiV62ai45rAJ2tMnUpY,9780
+finter/modeling/__init__.py,sha256=S8zJqi7UR0A0hearicFnrUOJF9EGloOciFpirP8pcTo,50
+finter/modeling/calendar.py,sha256=DpmyjAe3rU1exN99_9HfJniIW8q6zPod0mcKHcQaWgk,2001
+finter/models/__init__.py,sha256=kXOl_N4b68T7BHvJ018xETDbcDIwTvr-FtPrtPEJ0ug,3096
 finter/models/all_of_content_data_response_valid_data_graph.py,sha256=IbsH6lv04wjubwIHzRn0aK6XBSTzo_mYRWpj5vNtI98,3122
 finter/models/all_of_metafund_performance_response_threeyears.py,sha256=iZj-vtkpQSEoyK1SMEl6Oa2Cz4LvpzEeVMnm6bH8xHk,3219
 finter/models/alpha.py,sha256=3lnCmukiJZbPmYTNvSRlv-qhY4KJaHRiEUQYFcxDdWQ,4630
 finter/models/alpha_fields.py,sha256=pJQds4mpKvQtuozTkTKaGUbkSRVASMa4M1WsYbTRJcc,9841
 finter/models/alpha_identities_response.py,sha256=I4ovjwcvmUp7RF8UdqQpQospYCAdB8kyzaOt-h8gRJQ,4754
 finter/models/alpha_model_response.py,sha256=glxUXVxNwG5DAO7IXJE8VC_7bSkEv8RvkugwMJ2T8tc,4976
 finter/models/alpha_search_response.py,sha256=0-CNnOsZjM9d7S2n8PEV4krYb_iWhdp-yhCtueyrfmU,5379
 finter/models/alpha_simulation_request.py,sha256=cCCAH2zWEypMVT8-GAlEYurGUJ8noQ1yuCuEw9nYH-E,8384
 finter/models/alpha_simulation_response.py,sha256=0n4EihQgqXv6stgHxCVK4mx6aF0ErOnEjhcEM3Dbr04,7118
 finter/models/ap_position.py,sha256=9ER_oGMSSzB7JtypiPPrXKaCP0WcLHBhGKkZhyQphfo,6325
+finter/models/aws_credentials_response.py,sha256=b7t_qcgaVHKzDxhaSY60QyujBwd1-R-1094k4u-_ksg,5760
 finter/models/base_alpha_content_model_response.py,sha256=5l26t46FQnXNb4OFFzH4KGdrRtfOaC9A5Cd-KwvbBtI,6048
 finter/models/base_portfolio_get_alpha.py,sha256=3YqSkkHvjVoqa4TclUx-LcTuwBN9MsmWn3OnykZX4oU,9917
 finter/models/base_portfolio_model_response.py,sha256=2K15znVSNtZf1bfjynzTsrELAKP4RFg7nAQJPGNYUVs,6006
 finter/models/calendar_response.py,sha256=-DsMzWZq56KouzRgYC81PbcKM5aakeaaOGoSHOT6r7s,5787
+finter/models/code_response.py,sha256=RXlCw-EdaA5cm86mnt8lcumV9oQ-E84rAT461s7sJ6A,4436
 finter/models/content.py,sha256=k0pXo9bF2b_z2QK9sFPNVnQJH6OAB5UxXKh63kbdVKI,4668
 finter/models/content_category_response.py,sha256=zBYtaHm6QbUh9_YhwZz0E5xB862cltVrJ4WqEgQJ0Bc,4421
 finter/models/content_data.py,sha256=Iw1nFYcsjolsEsQBA_aSeSrlo6htlzmwqyZ6MQt88Ls,4130
 finter/models/content_data_request.py,sha256=X6CpOTq2nUGbh-YsvkEGb67gCivIL_oAzVk5qHttim8,3614
 finter/models/content_data_response.py,sha256=mBHQgE-MjYlL8UVJrgTcjnN4tIu2xXNNxj5v1nkmwAk,6505
 finter/models/content_fields.py,sha256=_O52RoZ7jmpfQv3TrxUXgRKNBz7YheuF-BbG44KoKF0,6910
 finter/models/content_identites_response.py,sha256=VHIONd456oV1nveZlSIF-iMoa2Kh_l2_4WJl9mwCZhY,4766
@@ -96,35 +111,35 @@
 finter/models/portfolio.py,sha256=jLhrt7cLeNE3A9m0QnOMRCbqXML0pKcCIs81l6pJLJ8,4706
 finter/models/portfolio_fields.py,sha256=MxQQ3FuTLV7zLXkUQWgx5gKy930JjiY5xIxEUJ4mkbQ,9345
 finter/models/portfolio_identities_response.py,sha256=S-VbVER9A2k0tYOmIXhLU0ymJ0GpEo7WswgHQDSsmDE,4802
 finter/models/portfolio_model_response.py,sha256=eJLB-9isPhuu1FMywfCas5BeGScAzX0SNZ7qQ_aXKPQ,5040
 finter/models/portfolio_search_response.py,sha256=OVGcAUXVUSwtVCbjevMaESZLRS8Hx-BxynP3hlYIRdc,5623
 finter/models/portfolio_simulation_request.py,sha256=tO-NKUUK-muvkqtogANjy_yrAh9Ia-oh12iQHmDKwyI,8528
 finter/models/portfolio_simulation_response.py,sha256=aJ5NOxJK_FlO7-QVMh8bdtfb9Q7ewcIzUC61VRwGvOU,6983
-finter/models/simulation_request.py,sha256=Ks8OiFlbnG2ydugZG5EF8Qqf9rf1cnccD2OB21wy0d4,16911
+finter/models/simulation_request.py,sha256=RNN-9GbckT7cRCfJwjGfU2MPTbM2OiEniO85UDci11o,17786
 finter/models/simulation_response.py,sha256=hn2gupS93FkBuBAGGelue0DJ2nMlM4NBSkUdtKeuQBM,4403
 finter/models/submission_request.py,sha256=3DZdRFwIFJIFxs298JlrPnq4MSYgSxs9_S3WxMHZwQA,4370
 finter/models/submission_response.py,sha256=-Y2LVE69pMP-W0QAgYmu-AJ-Dmpi0ms9QYXqeqtesOY,4403
 finter/models/table_data.py,sha256=JBuebia2rgwXAYWyBD7ph_ZWvO56Deoara8M86qg4KY,8538
 finter/models/trading_day_response.py,sha256=mpswIDaUG7EPR2EKEeTHxARCUjj0unxBjUXVlfbaaTA,5791
 finter/models/universe_response.py,sha256=44R3SEqWcbf9aneVmOt9eBd5ZIwEc2p98ywz-LPO2Wk,4376
 finter/models/user_login_request.py,sha256=MKjrv_Pd9UUpSqHSMwfB0MYEgOezRvAYLSrht7PBgwE,4253
 finter/models/user_login_response.py,sha256=15VLPIgVX1hycWy4o2BMGDcMYMCaOTqRPPQpow_2q7s,3438
 finter/models/wm_performance_request.py,sha256=c9O9DrEz8liqcmzX_rv9Q7eGflOtNhmQPcKrcwhpBeE,3525
 finter/models/wmap_performance_request.py,sha256=7NslSlZ-2JXYsBIAe1k3AR0phLQvT3q6J8M4jyMjgnc,4409
 finter/models/wmap_return_request.py,sha256=KbRJ-oo2rTZ8FO3B_0woRE4uj_Y4sIR9a3wxUhkLmIo,5029
 finter/models/wmap_return_response.py,sha256=02FoiNtkaC4adNvtIFfmpYeGANHQo2KEmUOStlvNyeQ,4340
-finter/utils/__init__.py,sha256=xTpJ93kppMPlj-V3jRQA_61TZiZCfQzjWSWtYAYbj5I,91
+finter/utils/__init__.py,sha256=IowZaauH0orMxUCe2NKV-HY--Kh1DQXG4BBOqcvMNqY,106
 finter/utils/convert.py,sha256=kOASm7y1VQtVCk1MugkpMWbHyJTuSKEHkjL4UJZMyio,1841
-finter/utils/func_utils.py,sha256=4ELI-geOCO4zNY6sRdNvjsRUx5B6BrUVZvIe4lATw6s,283
+finter/utils/func_utils.py,sha256=tG81HIwQaf13BOAzd4pSQXPPKbNViiL5krvdJYcjJxY,1560
 finter/utils/index.py,sha256=0_dhcGiDc9iultgR7gX3Mo9pLufQJBYD6G_pXw4xsCg,317
 finter/utils/timer.py,sha256=buLDFheg6cfzchjMrEbGeOQNvhrfeSvoqrwDHZBcjV0,543
 finter/utils/library/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finter/utils/library/context.py,sha256=WT8VnAB66s3SyYfMg6GgjXKFaIoEEpdgP16zpNUFp6w,1415
 finter/utils/model/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finter/utils/model/frames.py,sha256=fkrwcA1ouU4l85Dq2JdrSHXiAAA4-7rePRUChFMMujo,1079
 finter/utils/testing/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finter/utils/testing/format.py,sha256=uLAEtvwRtB-8GgDxfJbvF0mTV1InTurLjnGYRCgLPyE,302
-finter-0.1.9.dist-info/METADATA,sha256=t9joQV76FNf5dG-2u4khSa-imC32KJ_N1-Q-CR_Jibo,4107
-finter-0.1.9.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-finter-0.1.9.dist-info/top_level.txt,sha256=lA0aw9zmfOZ7bYgWiEmmJHvvWkzt9H3fSzQYX-AOr2s,7
-finter-0.1.9.dist-info/RECORD,,
+finter-0.2.0.dist-info/METADATA,sha256=PHrlKFe2tSwptItZLRwNMxtewRCPlnsU1qgE1gOw5uU,6557
+finter-0.2.0.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+finter-0.2.0.dist-info/top_level.txt,sha256=lA0aw9zmfOZ7bYgWiEmmJHvvWkzt9H3fSzQYX-AOr2s,7
+finter-0.2.0.dist-info/RECORD,,
```

